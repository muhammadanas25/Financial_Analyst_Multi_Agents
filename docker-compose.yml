version: '3.8'

services:
  weaviate:
    image: semitechnologies/weaviate:1.24.1
    container_name: fab-weaviate
    restart: on-failure:0
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: 'text2vec-openai'
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=3", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Optional: Transformer model for local embeddings (if not using OpenAI)
  # Uncomment if you want to use local embeddings instead of OpenAI
  # t2v-transformers:
  #   image: semitechnologies/transformers-inference:sentence-transformers-all-MiniLM-L6-v2
  #   container_name: fab-transformers
  #   environment:
  #     ENABLE_CUDA: '0'
  #   ports:
  #     - "8081:8080"

volumes:
  weaviate_data:
    driver: local
